{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da8edc3-8103-4523-8f5a-08f5ee4918d2",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe346d-c502-4c49-b026-3bb5007989e5",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting data from websites programmatically, usually through the use of software tools that automate the extraction process. The data that is extracted can be structured or unstructured, depending on the source of the data and the purpose of the scraping.\n",
    "\n",
    "Web scraping is used for a variety of reasons, such as:\n",
    "1. Data collection: Web scraping is commonly used to collect data from various websites, such as product information, news articles, and social media posts.\n",
    "\n",
    "2. Data analysis: The data collected through web scraping can be used for various types of analysis, such as sentiment analysis, trend analysis, and competitor analysis.\n",
    "\n",
    "3. Automation: Web scraping can also be used to automate repetitive tasks, such as monitoring price changes or tracking inventory levels.\n",
    "\n",
    "Some areas where web scraping is used are:\n",
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!\n",
    "\n",
    "4. Sentiment Analysis\n",
    "If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition.\n",
    "\n",
    "5. Email Marketing\n",
    "Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab50afb-7fa9-4d1e-9353-a0f7151fcb1e",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc840b-fb91-4a42-abb2-b5aefc3b200f",
   "metadata": {},
   "source": [
    "The methods used for Web Scraping are:\n",
    "\n",
    "- Using a web scraping framework or library\n",
    "- Using web scraping services\n",
    "- Using APIs\n",
    "- Using browser extensions\n",
    "- HTML Parsing\n",
    "- DOM Parsing\n",
    "- Vertical Aggregation\n",
    "- XPath\n",
    "- Google Sheets\n",
    "- HTTP Socket Programming\n",
    "- Semantic annotation recognizing\n",
    "- Computer vision web-page analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d9cc0-1901-4c2d-a808-e563a9930a87",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92455f36-6a5c-4e95-92a1-4fa5aa81f4fd",
   "metadata": {},
   "source": [
    "Beautiful Soup is a popular Python library that is used for web scraping purposes. It is designed to make it easy to extract data from HTML and XML documents.\n",
    "\n",
    "Web scraping involves the automated extraction of data from websites, typically for the purpose of analysis or integration with other systems. Beautiful Soup provides a simple interface for parsing and navigating HTML and XML documents, allowing developers to quickly extract the data they need.\n",
    "\n",
    "The library supports a range of parsing strategies, including HTML and XML parsers provided by Python's standard library as well as third-party parsers like lxml and html5lib. Beautiful Soup also includes a number of features that make it easy to navigate and manipulate parsed documents, including support for searching and filtering elements based on their attributes and contents.\n",
    "\n",
    "For example if you’ve found some webpages that display data relevant to your research, such as date or address information, but that do not provide any way of downloading the data directly. Beautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. It is a tool for web scraping that helps you clean up and parse the documents you have pulled down from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c546ddd-af19-4524-b313-eb0c5393df5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d677d38c-9878-47d5-834e-c899d32333e3",
   "metadata": {},
   "source": [
    "Flask is a lightweight and flexible Python web framework that is commonly used for developing web applications and APIs. Flask is a popular choice for web scraping projects due to its simplicity and ease of use. \n",
    "\n",
    "In a web scraping project, Flask can be used to build a simple web server that accepts requests for specific data, scrapes that data from websites, and returns the scraped data as a response to the client. Flask provides a range of features, such as route handling, HTTP request handling, and URL routing, that make it easy to build such a web server.\n",
    "\n",
    "Additionally, Flask can be used to integrate the scraped data with other web applications or databases. Flask's flexibility allows developers to easily extend its functionality and integrate it with other tools and technologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bab8a7-2294-4925-8df0-ab0a396a4f67",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0fd6e-254b-4ca4-90dc-b07710a890a2",
   "metadata": {},
   "source": [
    "Here we used two AWS services in this project.\n",
    "1. CodePipeline\n",
    "2. Elastic Beanstalk\n",
    "\n",
    "1. CodePipeline\n",
    "- AWS CodePipeline is a fully managed continuous delivery service that helps you automate your software release process for fast and reliable application and infrastructure updates. \n",
    "- It is designed to help you efficiently manage and automate the steps required to release your software changes, such as building and testing your code, deploying your application, and validating your code changes.\n",
    "- Here, we used CodePipeline to send our code (act as a mediator) from Github Repositary to Elastic Beanstalk for Deployment\n",
    "\n",
    "2. Elastic Beanstalk\n",
    "- Elastic Beanstalk is a fully managed service offered by Amazon Web Services (AWS) that makes it easy to deploy, manage, and scale web applications and services developed in various programming languages, including Java, Python, Node.js, Ruby, .NET, and PHP.\n",
    "- Here, we used Beanstalk to for Environment setup required to deploy our app on AWS cloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
